---
title: "AFL Modelling"
output:
  pdf_document: default
  html_notebook: default
---
```{r}
source("../../utilities/DBDA2E-utilities.R")
source("../../utilities/MoreUtilities.R")
library(ggplot2)
library(ggpubr)
library(ks)
library(rjags)
library(runjags)
library(benchmarkme)
```

Read train and test sets from files.
```{r}
train <- read.csv("../../data/train_stats_per_career.csv")
test <- read.csv("../../data/test_stats_per_career.csv")
```

# Modelling
```{r}
train2 <- subset(train, select=-c(Brownlow.Votes))
test2 <- subset(test, select=-c(Brownlow.Votes))
y <- train$Brownlow.Votes
x <- as.matrix(train2[,3:23])
xPred = as.matrix(test2[,3:23])


dataList = list(
  x = x,
  y = y,
  xPred = xPred,
  rowCount = length(y),
  colCount = ncol(x), 
  predCount = nrow(xPred)
)

```



### JAGS Model
```{r}
	modelString = "
	data {
	  yMean <- mean(y)
	 
	  # Specify the priors for original beta parameters
	  # Prior locations to reflect the expert information
	  # Regression coeffient in LR indicates how much 1 unit of change of the 
	  # predictor increases the log odds of outcome 1.
	  # Set to overall mean a priori based on the interpretation of constant term in regression
	  
	  # mu0 <- yMean 
	  # mu[1] <- 16.37
	  # mu[2] <- 9.359
	  # mu[3] <- 4.009
	  # mu[4] <- 7.01
	  # mu[5] <- 0.5516
	  # mu[6] <- 0.37973
	  # mu[7] <- 1.735
	  # mu[8] <- 2.875
	  # mu[9] <- 1.599
	  # mu[10] <- 2.286
	  # mu[11] <- 1.663
	  # mu[12] <- 2.274
	  # mu[13] <- 0.8302
	  # mu[14] <- 0.8329
	  # mu[15] <- 6.276
	  # mu[16] <- 9.992
	  # mu[17] <- 0.487
	  # mu[18] <- 0.511
	  # mu[19] <- 2.154
	  # mu[20] <- 0.3222
	  # mu[21] <- 0.3769
	  
	  mu0 <- yMean
	  mu[1] <- 15
	  mu[2] <- 10
	  mu[3] <- 5
	  mu[4] <- 0.7
	  mu[5] <- 0.5
	  mu[6] <- 2
	  mu[7] <- 4
	  mu[8] <- 1
	  mu[9] <- 2
	  mu[10] <- 1
	  mu[11] <- 1.5
	  mu[12] <- 1.3
	  mu[13] <- 1.3
	  mu[14] <- 7
	  mu[15] <- 10
	  mu[16] <- 1
	  mu[17] <- 3
	  mu[18] <- 0.8
	  mu[19] <- 1.5
	  mu[20] <- 0.3
	  mu[21] <- 0.5
	  
	  
	  
	  # Prior Variances to reflect the expert information
	  Var0   <- 1.00000 # Set simply to 1
	  for (i in 1:colCount) {
	    Var[i] <- 0.25
	  }
	}
	# Model
	model {
	  beta0   ~ dnorm(mu0,  1/Var0)
	  for (j in 1:colCount) {
	    beta[j] ~ dnorm(mu[j], 1/Var[j])
	    }
	  
	  
	  # ... Variance as it is ...
	  precision ~ dexp(1/0.25) 
	  
	  for (i in 1:rowCount) {
	  
	    # Normal Likelihood
	    #for (i in 1:rowCount) {
	    #beta0   ~ dnorm(mu0,  1/Var0) + a 
	    y[i] ~ dnorm(beta0 + sum(beta[1:colCount]*x[i,1:colCount]) , precision)
	  }
	    # Compute predictions at every step of the MCMC
  for (k in 1:predCount) {
    pred[k] <- beta0 + sum(beta[1:colCount]*xPred[k,1:colCount])
  }
	}
"
	
	writeLines(modelString, con="TEMPmodel.txt")
```
### Run JAGS
```{r}

graphics.off()
 
parameters = c("beta0")
 for ( i in 1:21){
  parameters = c(parameters, paste0("beta[",i,"]"))
}
 
 for ( i in 1:nrow(xPred)){
   parameters = c(parameters, paste0("pred[",i,"]"))
 }


adaptSteps = 2000
burnInSteps = 4000
nChains = 10
thinSteps = 200
numSavedSteps = 4000

nIter = ceiling( ( numSavedSteps * thinSteps ) / nChains )

startTime = proc.time()
# sink("debug2.txt")
runJagsOut <- run.jags( method="parallel" ,
                        model="TEMPmodel.txt" ,
                        monitor=parameters  ,
                        data=dataList ,
                        n.chains=nChains ,
                        adapt=adaptSteps ,
                        burnin=burnInSteps ,
                        sample=numSavedSteps ,
                        thin=thinSteps , summarise=FALSE , plots=FALSE )
stopTime = proc.time()
duration = stopTime - startTime
show(duration)
codaSamples = as.mcmc.list( runJagsOut )
# sink()
# save( codaSamples , file=paste("A2Run4","Mcmc.Rdata",sep="") )
# save.image(file='A2Run4.RData')
```

### Results
```{r}
graphics.off()

diagMCMC( codaSamples , parName="beta0" )
for ( i in 1:22){
  diagMCMC( codaSamples , parName=paste0("beta[",i,"]") )
}
```

``` {r}
diagMCMC( codaSamples )
for ( i in 1:22){
  diagMCMC( codaSamples , parName=paste0("pred[",i,"]") )
}
```

```{r}

graphics.off()

compVal <- data.frame("beta0" = 1, "beta[1]" = 0, "beta[2]" = 0, "beta[3]" = 0, "beta[4]" =  0, "beta[5]" = 0, 
                      "beta[6]" = 0, "beta[7]" = 0, "beta[8]" = 0, "beta[9]" =  0, "beta[10]" = 0,
                      "beta[11]" = 0, "beta[12]" = 0, "beta[13]" = 0, "beta[14]" =  0, "beta[15]" = 0,
                      "beta[16]" = 0, "beta[17]" = 0, "beta[18]" = 0, "beta[19]" =  0, "beta[20]" = 0,
                      "beta[21]" = 0, "beta[22]" = 0,
                      check.names=FALSE)
summaryInfo <- smryMCMC( codaSamples = codaSamples , compVal = compVal, saveName="SummaryInfo" )
summaryInfo
```

```{r}
graphics.off()
plotMCMC_HD( codaSamples = codaSamples, data = train, xName=c("Disposals", "Kicks", "Marks", "Handballs", "Goals", "Behinds",
    "Hit.Outs", "Tackles", "Rebounds", "Inside.50s", "Clearances", "Clangers",
    "Frees", "Frees.Against", "Contested.Possessions", "Uncontested.Possessions", "Contested.Marks", "Marks.Inside.50", "One.Percenters", "Bounces",
    "Goal.Assists") ,
             yName="Brownlow.Votes", compVal = compVal, preds = TRUE)
```

# ============ Predictive check ============
```{r}

modes = summaryInfo[,"Mode"]
# 14 is the number of rows skipping beta and heading rows = (6 + 5 + 2)
predictions = modes[24:length(modes) - 1]
real = c(test$Brownlow.Votes)
length(predictions)
length(real)
n = length(real)
# MAE
sum(abs(predictions - real))/n
# MSE
mse = sum((real - predictions)^2)
mse
# RMSE
sqrt(mse/n)
```