
	data {
	  yMean <- mean(y)
	 
	  # Specify the priors for original beta parameters
	  # Prior locations to reflect the expert information
	  # Regression coeffient in LR indicates how much 1 unit of change of the 
	  # predictor increases the log odds of outcome 1.
	  # Set to overall mean a priori based on the interpretation of constant term in regression
	  
	  mu0 <- yMean 
	  mu[1] <- 0
	  mu[2] <- 2
	  mu[3] <- 2
	  mu[4] <- 1
	  mu[5] <- 2
	  mu[6] <- 3
	  mu[7] <- 1
	  mu[8] <- 0
	  mu[9] <- 1
	  mu[10] <- 0
	  mu[11] <- 2
	  mu[12] <- 3
	  mu[13] <- 1
	  mu[14] <- 1
	  mu[15] <- 0
	  mu[16] <- 3
	  mu[17] <- 1
	  mu[18] <- 1
	  mu[19] <- 2
	  mu[20] <- 0
	  mu[21] <- 1
	  mu[22] <- 1
	  
	  # Prior variances to reflect the expert information
	  Var0   <- 1.00000 # Set simply to 1
	  for (i in 1:colCount) {
	    var[i] <- 0.25
	  }  
	}
	# Model
	model {
	  beta0   ~ dnorm(mu0,  1/Var0)
	  for (j in 1:colCount) {
	    beta[j] ~ dnorm(mu[j], 1/var[j])
	    }
	  }
	  
	  
	  # ... variance as it is ...
	  precision ~ dexp(1/0.25) 
	  
	  for (i in 1:rowCount) {
	  
	    # Normal Likelihood
	    #for (i in 1:rowCount) {
	    #beta0   ~ dnorm(mu0,  1/Var0) + a 
	    y[i] ~ dnorm(beta0 + sum(beta[1:colCount]*x[i,1:colCount]) , precision)
	  }
	    # Compute predictions at every step of the MCMC
	    # HOW DO I MAKE THIS INTO A FOR LOOP AAAAAAA
  for (k in 1:predCount) {
    pred[k] <- beta0 + sum(beta[1:colCount]*xPred[k,1:colCount])
  }

}
